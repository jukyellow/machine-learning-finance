{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Pytorch_Linear_Regression_20201113.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "11Y2EM0UdMNN"
      },
      "source": [
        "#https://www.youtube.com/watch?v=kyjBMuNM1DI&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=4\n",
        "#https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-02_linear_regression.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LaJSavtd0N3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZnoXzH_d0P_",
        "outputId": "ca0ee8a8-c4c6-4330-94d7-d1f37ecd4e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f30fa32d570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thM-xQL9fHCd",
        "outputId": "13ef0d3e-e5ab-4b01-d25a-928c28265467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "print(x_train)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PXuq-OBfHEp",
        "outputId": "d61c12b1-c29e-4071-d349-5bab0c929db3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Weight Initialization¶\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "print(W)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n",
            "tensor([0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMJM-BwSfHI1",
        "outputId": "2eca55b6-c422-42f8-8757-afebc49a94e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Hypothesis¶\n",
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azS-VofJfHHp",
        "outputId": "e5f32968-9594-4028-8db2-4210302aa278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Cost\n",
        "print(hypothesis - y_train)\n",
        "print((hypothesis - y_train) ** 2)\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.],\n",
            "        [-2.],\n",
            "        [-3.]], grad_fn=<SubBackward0>)\n",
            "tensor([[1.],\n",
            "        [4.],\n",
            "        [9.]], grad_fn=<PowBackward0>)\n",
            "tensor(4.6667, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muMU6QXAfWmP",
        "outputId": "ddadbb16-adc5-446a-c086-76fc298c1ce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Gradient Descent\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "cost.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(W)\n",
        "print(b)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0933], requires_grad=True)\n",
            "tensor([0.0400], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy07c1MqfWog",
        "outputId": "ab42b695-b59f-4e5b-f171-e03534709944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Let's check if the hypothesis is now better.\n",
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)\n",
        "\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1333],\n",
            "        [0.2267],\n",
            "        [0.3200]], grad_fn=<AddBackward0>)\n",
            "tensor(3.6927, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xw8DnoUf3Rl",
        "outputId": "54a2f8c7-d6cb-4206-d0a8-4d895885fb0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Training with Full Code\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
            "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
            "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
            "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
            "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
            "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
            "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
            "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
            "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
            "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
            "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQQ-wRjEgDyW",
        "outputId": "78cebd59-0f89-4931-99c2-71d4bbf38e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# High-level Implementation with nn.Module\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = LinearRegressionModel()\n",
        "hypothesis = model(x_train)\n",
        "print(hypothesis)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyJDVrY4gD1R",
        "outputId": "f2c7f390-cf6c-4429-e592-1692bc7e5829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(hypothesis)\n",
        "print(y_train)\n",
        "\n",
        "cost = F.mse_loss(hypothesis, y_train) #MSE 역시 PyTorch에서 기본적으로 제공한다.\n",
        "print(cost)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward>)\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "tensor(2.1471, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZlf3UzshG8m"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer.zero_grad()\n",
        "cost.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmBZZ0FIhK3G",
        "outputId": "ee12bd5b-9cdc-4dc3-bcbb-99b60b6bb09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Training with Full Code¶\n",
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# 모델 초기화\n",
        "model = LinearRegressionModel()\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "    \n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        params = list(model.parameters())\n",
        "        W = params[0].item()\n",
        "        b = params[1].item()\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W, b, cost.item()\n",
        "        ))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: -0.101, b: 0.508 Cost: 4.630286\n",
            "Epoch  100/1000 W: 0.713, b: 0.653 Cost: 0.061555\n",
            "Epoch  200/1000 W: 0.774, b: 0.514 Cost: 0.038037\n",
            "Epoch  300/1000 W: 0.822, b: 0.404 Cost: 0.023505\n",
            "Epoch  400/1000 W: 0.860, b: 0.317 Cost: 0.014525\n",
            "Epoch  500/1000 W: 0.890, b: 0.250 Cost: 0.008975\n",
            "Epoch  600/1000 W: 0.914, b: 0.196 Cost: 0.005546\n",
            "Epoch  700/1000 W: 0.932, b: 0.154 Cost: 0.003427\n",
            "Epoch  800/1000 W: 0.947, b: 0.121 Cost: 0.002118\n",
            "Epoch  900/1000 W: 0.958, b: 0.095 Cost: 0.001309\n",
            "Epoch 1000/1000 W: 0.967, b: 0.075 Cost: 0.000809\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}